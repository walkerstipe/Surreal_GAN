{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi-Task_NETWORK",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUYEXXRbfYluwulMVJ0Whw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/walkerstipe/Surreal_GAN/blob/main/Multi_Task_NETWORK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij7JnqIycehT"
      },
      "source": [
        "#two 'heads' that each have different reward functions/targets\n",
        "#similar to ensemble learning methinks but lets search around and see what there is (pretty sure ive done \n",
        "#a bunch of this shit before but can't recall)\n",
        "\n",
        "#notes, actor critic, (ddpg particulalry), are really quite similar in some regards. \n",
        "\n",
        "#update: seems we dont want stopgradient (we want those gradients) and 'trainable' \n",
        "#is great but cant be adjusted after initialization, (immutable tensors)\n",
        "#next trying to use copying of weights and inserting new layers (indexing ok prob?)\n",
        "  #1. initialize layer with specific weights\n",
        "  #2. insert layer into existing net, replacing previous layer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03sZx4Xvm52s"
      },
      "source": [
        "# #behold my sexy network diagram in asci. \n",
        "# # each input section is a task\n",
        "# #1. subnetwork trained on a task or simple problem\n",
        "# .  .  .  .      \n",
        "# |   |  |  |    \n",
        "# .  .  .  .       \n",
        "# |   |  |  |    \n",
        "# .  .  .  .     \n",
        "# .  .  .  . \n",
        "# |   |  |  |\n",
        "# .  .  .  . \n",
        "# |   |  |  |\n",
        "# .  .  .  . \n",
        "\n",
        "\n",
        "\n",
        "# #\"ensemble\" of learners, (basically multiple personalities... literally though)\n",
        "# .  .  .  .     .  .  .  .      .  .  .  .     .  .  .  .  \n",
        "# |   |  |  |    |   |  |  |     |   |  |  |    |   |  |  |\n",
        "# .  .  .  .     .  .  .  .      .  .  .  .     .  .  .  .  \n",
        "# |   |  |  |    |   |  |  |     |   |  |  |    |   |  |  |\n",
        "# .  .  .  .     .  .  .  .      .  .  .  .     .  .  .  .     \n",
        "#                 .  .  .  .     .  .  .  .  \n",
        "#                 |   |  |  |    |   |  |  |                 #feature extraction and mixing of the minds layer. grow this over time?\n",
        "#                 .  .  .  .     .  .  .  .                  #synesthesia is a feature\n",
        "#                 |   |  |  |    |   |  |  |                 #the curse of dimensionality has not been solved, (progress sure but not solved)\n",
        "#                 .  .  .  .     .  .  .  . \n",
        "# .  .  .  .     .  .  .  .      .  .  .  .     .  .  .  .  \n",
        "# |   |  |  |    |   |  |  |     |   |  |  |    |   |  |  |\n",
        "# .  .  .  .     .  .  .  .      .  .  .  .     .  .  .  .  \n",
        "# |   |  |  |    |   |  |  |     |   |  |  |    |   |  |  |\n",
        "# .  .  .  .     .  .  .  .      .  .  .  .     .  .  .  .  "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx3PbIdfvKis"
      },
      "source": [
        "# #starting simple, can i interleave a MODEL into the hidden layers (middle bit) of another network? (and keep them\n",
        "# #independent as models but still share weights)\n",
        "# #\"progressive growing gans\" is similar example starting there\n",
        "\n",
        "# #1. simple net\n",
        "# .  .  .  .      \n",
        "# |   |  |  |    \n",
        "# .  .  .  .       \n",
        "# |   |  |  |    \n",
        "# .  .  .  .     \n",
        "# .  .  .  . \n",
        "# |   |  |  |\n",
        "# .  .  .  . \n",
        "# |   |  |  |\n",
        "# .  .  .  . \n",
        "\n",
        "# #2. simple net with added model in the middle bit\n",
        "# .  .  .  .      \n",
        "# |   |  |  |    \n",
        "# .  .  .  .       \n",
        "# |   |  |  |    \n",
        "# .  .  .  .     \n",
        "# .  .  .  . \n",
        "# |   |  |  |\n",
        "# .  .  .  . \n",
        "# |   |  |  |\n",
        "# .  .  .  . \n",
        "# .  .  .  .      \n",
        "# |   |  |  |    \n",
        "# .  .  .  .       \n",
        "# |   |  |  |    \n",
        "# .  .  .  .     "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3R0y5wuzh2a-",
        "outputId": "413c48c5-18b7-44e5-accd-f1fc75fcb23a"
      },
      "source": [
        "# insert NETWORK (model) not just layer\n",
        "# see if possible to keep as independent\n",
        "from sklearn.datasets import make_blobs\n",
        "import tensorflow\n",
        "!pip install keras.utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot\n",
        "from os import makedirs\n",
        "from numpy.random import randn\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import estimator\n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "\n",
        "# generate 2d classification dataset\n",
        "X, y = make_blobs(n_samples=1100, centers=3, n_features=3, cluster_std=2, random_state=2)\n",
        "\n",
        "# one hot encode output variable\n",
        "y = to_categorical(y)\n",
        "\n",
        "# split into train and test\n",
        "n_train = 100\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "\n",
        "# fit model\n",
        "def make_mod(trainX, trainy):\n",
        "  #model = Sequential()\n",
        "  #my_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
        "  my_input = keras.Input(shape=(3))#, name=\"img\")\n",
        "  #model.add(Dense(3, input_dim=3, activation='relu'))\n",
        "\n",
        "  #x = layers.Conv2D(16, 3, activation=\"relu\")(my_input)\n",
        "  x_0 = layers.Dense(3, activation=\"relu\")(my_input)\n",
        "  x_1 = layers.Dense(3, activation=\"relu\")(my_input)\n",
        "  x_2 = layers.Dense(3, activation=\"relu\")(my_input)\n",
        "  #x = tf.stop_gradient(layers.Dense(3, activation=\"relu\")(my_input))\n",
        "  #model.add(Dense(3, input_dim=3, activation='relu'))\n",
        "  \n",
        "  #x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
        "  my_output = layers.Dense(3, activation=\"softmax\")(x_2)\n",
        "  #model.add(Dense(3, activation='softmax'))\n",
        "  my = keras.Model(my_input, my_output, name=\"my\")\n",
        "  my.summary()\n",
        "  print(\"weights before training: \", my.layers[1].weights)\n",
        "\n",
        "  yawg = []\n",
        "  yawg.append(my.layers[1].weights)\n",
        "\n",
        "  my.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  my.fit(trainX, trainy, epochs=50, batch_size=1, verbose=0)\n",
        "#need to np.copy/deepcopy\n",
        "#it's read only... wut?\n",
        "  #is it just Sequential models that are immutable? swap to functional and all good?...\n",
        "\n",
        "  #\"All tensors are immutable like Python numbers and strings: you can never update \n",
        "  #the contents of a tensor, only create a new one.\"\n",
        "  #possible to replace single layer?... (or is the whole thing considered a tensor together and thereby completely immutable...)\n",
        "  my.layers[1].weights = yawg[0]\n",
        "  print(\"weights after training: \", my.layers[1].weights)\n",
        "  return my #model\n",
        "\n",
        "model_0 = make_mod(trainX, trainy)\n",
        "#tf.stop_gradient(model_0.layers[2].weights)\n",
        "_, acc = model_0.evaluate(testX, testy, verbose=2)\n",
        "print(\"weights after training: \", model_0.layers[1].weights)\n",
        "\n",
        "print(acc)\n",
        "model_1 = make_mod(trainX, trainy)\n",
        "_, acc = model_1.evaluate(testX, testy, verbose=2)\n",
        "print(acc)\n",
        "print(model_0.layers[0].weights)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras.utils\n",
            "  Downloading keras-utils-1.0.13.tar.gz (2.4 kB)\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.7/dist-packages (from keras.utils) (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras.utils) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras.utils) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras.utils) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras.utils) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->Keras>=2.1.5->keras.utils) (1.5.2)\n",
            "Building wheels for collected packages: keras.utils\n",
            "  Building wheel for keras.utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras.utils: filename=keras_utils-1.0.13-py3-none-any.whl size=2656 sha256=be0d54032f58b49b8322360f0c1f6bb9c342268b8b7d47ed3bb696a55ef88965\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/dd/3b/493952a5240d486a83805d65360dedadbadeae71d25e2c877f\n",
            "Successfully built keras.utils\n",
            "Installing collected packages: keras.utils\n",
            "Successfully installed keras.utils-1.0.13\n",
            "Model: \"my\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 3)]               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 24\n",
            "Trainable params: 24\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "weights before training:  [<tf.Variable 'dense_2/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
            "array([[ 0.90675855,  0.10235715, -0.43588996],\n",
            "       [ 0.8501849 , -0.9922452 ,  0.8600254 ],\n",
            "       [-0.01689601,  0.5567682 ,  0.9152994 ]], dtype=float32)>, <tf.Variable 'dense_2/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2718\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2719\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoTrackable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2720\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: can't set attribute",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-183e979b221a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmy\u001b[0m \u001b[0;31m#model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mmodel_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;31m#tf.stop_gradient(model_0.layers[2].weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-183e979b221a>\u001b[0m in \u001b[0;36mmake_mod\u001b[0;34m(trainX, trainy)\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0;31m#the contents of a tensor, only create a new one.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;31m#possible to replace single layer?... (or is the whole thing considered a tensor together and thereby completely immutable...)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0mmy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myawg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weights after training: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmy\u001b[0m \u001b[0;31m#model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2722\u001b[0m             ('Can\\'t set the attribute \"{}\", likely because it conflicts with '\n\u001b[1;32m   2723\u001b[0m              \u001b[0;34m'an existing read-only @property of the object. Please choose a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2724\u001b[0;31m              'different name.').format(name))\n\u001b[0m\u001b[1;32m   2725\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Can't set the attribute \"weights\", likely because it conflicts with an existing read-only @property of the object. Please choose a different name."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIQtfjQxvT0K",
        "outputId": "30ef0f28-794f-4a24-a908-10a58168603f"
      },
      "source": [
        "layer1 = keras.layers.Dense(3, activation=\"relu\")\n",
        "layer2 = keras.layers.Dense(3, activation=\"sigmoid\")\n",
        "model = keras.Sequential([keras.Input(shape=(3,)), layer1, layer2])\n",
        "print('before training: ', layer1.weights)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
        "print('after training: ', model.layers[1].weights)\n",
        "\n",
        "\n",
        "#layer1_2 = keras.layers.Dense(3, activation=\"relu\", weights = layer1.weights)\n",
        "layer1_2 = keras.layers.Dense(3, activation=\"relu\")\n",
        "#layer2_2 = keras.layers.Dense(3, activation=\"sigmoid\", weights = model.layers[1].weights)\n",
        "layer2_2 = keras.layers.Dense(3, activation=\"sigmoid\")\n",
        "\n",
        "model_2 = keras.Sequential([keras.Input(shape=(3,)), layer1_2, layer2_2])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "before training:  [<tf.Variable 'dense_20/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
            "array([[ 0.46883798, -0.29093933, -0.05204535],\n",
            "       [-0.77176094, -0.02694535,  0.31962752],\n",
            "       [-0.14452934,  0.2867167 , -0.19020152]], dtype=float32)>, <tf.Variable 'dense_20/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n",
            "WARNING:tensorflow:6 out of the last 5005 calls to <function Model.make_train_function.<locals>.train_function at 0x7f67cd7b4cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.0481\n",
            "after training:  [<tf.Variable 'dense_21/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
            "array([[ 0.30250472, -0.3535108 , -0.9290188 ],\n",
            "       [ 0.4720137 ,  0.6499977 , -0.17250347],\n",
            "       [ 0.08599003, -0.37113804, -0.8853477 ]], dtype=float32)>, <tf.Variable 'dense_21/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.00099987, -0.00099969, -0.00099993], dtype=float32)>]\n",
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.0626\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f67cdb2e050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "neo_UajWGgX0",
        "outputId": "1a7c571b-bdf3-4ba4-a07c-7c6c90f280d7"
      },
      "source": [
        "# Make a model with 2 layers\n",
        "layer1 = keras.layers.Dense(3, activation=\"relu\")\n",
        "layer2 = keras.layers.Dense(3, activation=\"sigmoid\")\n",
        "tf.stop_gradient(layer2.weights)\n",
        "#tf.stop_gradient(model_0.layers[0].weights)\n",
        "model = keras.Sequential([keras.Input(shape=(3,)), layer1, layer2])\n",
        "print('before training: ', layer1.weights)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
        "print('after training: ', model.layers[1].weights)\n",
        "\n",
        "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
        "print('no stop_grad: ', model.layers[1].weights)\n",
        "\n",
        "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
        "tf.stop_gradient(model.layers[1].weights)\n",
        "print('with stop_grad: ', model.layers[1].weights)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "before training:  [<tf.Variable 'dense_13/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
            "array([[-0.36368108,  0.66787887,  0.28092766],\n",
            "       [-0.23105717, -0.83103824,  0.31745648],\n",
            "       [ 0.56801176, -0.44976997,  0.9670644 ]], dtype=float32)>, <tf.Variable 'dense_13/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n",
            "WARNING:tensorflow:5 out of the last 5008 calls to <function Model.make_train_function.<locals>.train_function at 0x7fc636485710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.0806\n",
            "after training:  [<tf.Variable 'dense_14/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
            "array([[ 0.3515756 , -0.31720096, -0.88685733],\n",
            "       [ 0.78182554,  0.9851663 ,  0.66817737],\n",
            "       [-0.46885931, -0.68534786,  0.07711408]], dtype=float32)>, <tf.Variable 'dense_14/bias:0' shape=(3,) dtype=float32, numpy=array([-0.00099989,  0.00099987,  0.00099993], dtype=float32)>]\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1144\n",
            "no stop_grad:  [<tf.Variable 'dense_14/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
            "array([[ 0.3509072 , -0.3165318 , -0.886188  ],\n",
            "       [ 0.7810815 ,  0.98442227,  0.66743344],\n",
            "       [-0.46878424, -0.6854428 ,  0.0781133 ]], dtype=float32)>, <tf.Variable 'dense_14/bias:0' shape=(3,) dtype=float32, numpy=array([-0.00197176,  0.00070471,  0.00171563], dtype=float32)>]\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1a9934e79429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'with stop_grad: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstop_gradient\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m  10308\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10309\u001b[0m       return stop_gradient_eager_fallback(\n\u001b[0;32m> 10310\u001b[0;31m           input, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m  10311\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10312\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstop_gradient_eager_fallback\u001b[0;34m(input, name, ctx)\u001b[0m\n\u001b[1;32m  10342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10343\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstop_gradient_eager_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10344\u001b[0;31m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10345\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10346\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         tensor = ops.convert_to_tensor(\n\u001b[0;32m--> 274\u001b[0;31m             t, dtype, preferred_dtype=default_dtype, ctx=ctx)\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m       \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1534\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cast_nested_seqs_to_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"packed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;31m# checking.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_or_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_or_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m   \u001b[0mmust_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m   \u001b[0mconverted_elems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mpack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   6398\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6399\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6400\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6401\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6402\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6895\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6896\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6897\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6898\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Shapes of all inputs must match: values[0].shape = [3,3] != values[1].shape = [3] [Op:Pack] name: packed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pac8Hz_O9xuE"
      },
      "source": [
        "tf.stop_gradient(model_0.layers[0].weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgCHSdhOIjAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed3dec0-a1b4-4838-acc4-e718f5920982"
      },
      "source": [
        "layer = keras.layers.Dense(3)\n",
        "layer.build((None, 4))  # Create the weights\n",
        "layer.trainable = False  # Freeze the layer\n",
        "\n",
        "print(\"weights:\", len(layer.weights))\n",
        "print(\"trainable_weights:\", len(layer.trainable_weights))\n",
        "print(\"non_trainable_weights:\", len(layer.non_trainable_weights))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights: 2\n",
            "trainable_weights: 0\n",
            "non_trainable_weights: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVEC9gMPMthA"
      },
      "source": [
        "# #original archived\n",
        "# # Make a model with 2 layers\n",
        "# layer1 = keras.layers.Dense(3, activation=\"relu\")\n",
        "# layer2 = keras.layers.Dense(3, activation=\"sigmoid\")\n",
        "# model = keras.Sequential([keras.Input(shape=(3,)), layer1, layer2])\n",
        "\n",
        "# # Freeze the first layer\n",
        "# layer1.trainable = False\n",
        "\n",
        "# # Keep a copy of the weights of layer1 for later reference\n",
        "# initial_layer1_weights_values = layer1.get_weights()\n",
        "\n",
        "# # Train the model\n",
        "# model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "# model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
        "\n",
        "# # Check that the weights of layer1 have not changed during training\n",
        "# final_layer1_weights_values = layer1.get_weights()\n",
        "# np.testing.assert_allclose(\n",
        "#     initial_layer1_weights_values[0], final_layer1_weights_values[0]\n",
        "# )\n",
        "# np.testing.assert_allclose(\n",
        "#     initial_layer1_weights_values[1], final_layer1_weights_values[1]\n",
        "# )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ2sObwUIwDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c67559e-195f-4eab-c4cb-24a9605c9e5b"
      },
      "source": [
        "# Make a model with 2 layers\n",
        "layer1 = keras.layers.Dense(3, activation=\"relu\")\n",
        "layer2 = keras.layers.Dense(3, activation=\"sigmoid\")\n",
        "model = keras.Sequential([keras.Input(shape=(3,)), layer1, layer2])\n",
        "\n",
        "layer1.trainable = True\n",
        "\n",
        "print(layer1.weights)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
        "\n",
        "print(model.layers[1].weights)\n",
        "model.layers[1].trainable = False \n",
        "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
        "print(model.layers[1].weights)\n",
        "\n",
        "model.layers[1].trainable = False \n",
        "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
        "print(model.layers[1].weights)\n",
        "#wut...\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "[<tf.Variable 'dense_5/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
            "array([[ 0.05617666, -0.10382462, -0.5446832 ],\n",
            "       [-0.1262505 ,  0.12848854,  0.88347125],\n",
            "       [ 0.7048845 ,  0.33851194,  0.86311436]], dtype=float32)>, <tf.Variable 'dense_5/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1439\n",
            "[<tf.Variable 'dense_6/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
            "array([[ 0.14261097,  0.8747211 ,  0.2584371 ],\n",
            "       [-0.46983382,  0.0594026 , -0.5868757 ],\n",
            "       [-0.8388236 , -0.5035944 ,  0.5075929 ]], dtype=float32)>, <tf.Variable 'dense_6/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.00099994, -0.00099994, -0.00099985], dtype=float32)>]\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0778\n",
            "[<tf.Variable 'dense_6/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
            "array([[ 0.14324905,  0.87386763,  0.25769845],\n",
            "       [-0.46914893,  0.05856382, -0.58734673],\n",
            "       [-0.83808696, -0.5044103 ,  0.50751054]], dtype=float32)>, <tf.Variable 'dense_6/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.00156088, -0.00192716, -0.00128592], dtype=float32)>]\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0325\n",
            "[<tf.Variable 'dense_6/kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
            "array([[ 0.14368372,  0.87333465,  0.25687057],\n",
            "       [-0.46863848,  0.05805961, -0.58807766],\n",
            "       [-0.8374807 , -0.50488627,  0.506994  ]], dtype=float32)>, <tf.Variable 'dense_6/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.00198294, -0.00250841, -0.00186124], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F04hl_irD5mz"
      },
      "source": [
        "# Make a model with 2 layers\n",
        "layer1 = keras.layers.Dense(3, activation=\"relu\")\n",
        "layer2 = keras.layers.Dense(3, activation=\"sigmoid\")\n",
        "model = keras.Sequential([keras.Input(shape=(3,)), layer1, layer2])\n",
        "\n",
        "layer1.trainable = False\n",
        "\n",
        "print(layer1.weights)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
        "\n",
        "print(model.layers[0].weights)\n",
        "layer1.trainable = False\n",
        "model.layers[0].trainable = False \n",
        "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
        "print(model.layers[0].weights)\n",
        "\n",
        "layer1.trainable = True\n",
        "model.layers[0].trainable = True \n",
        "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
        "print(model.layers[0].weights)\n",
        "#wut...\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A03ibTAgFXGN"
      },
      "source": [
        "print(layer1.weights)\n",
        "print(model.layers[0].weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuPKoqOxT1VL"
      },
      "source": [
        "print(model_0.layers[1].weights)\n",
        "\n",
        "#x = np.copy(model_0.layers.weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2K-7myzvqZN"
      },
      "source": [
        "#why are the weight values changing... seems the variables might need to be 'copied'... shame\n",
        "# array([[ 1.1752876 , -1.4872373 , -7.0670514 ],\n",
        "#        [ 0.8589232 ,  0.78620785, -9.0647745 ],\n",
        "#        [ 3.033589  , -2.9427311 , -2.1299865 ]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCWPrywii0ey"
      },
      "source": [
        "for layer in model_0.layers:\n",
        "  print(layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYQXLjnN2S-f"
      },
      "source": [
        "# #model_0.layers[1].output\n",
        "# #model_0.add(Dense(3, activation='softmax'))\n",
        "# model_0.add(model_1.layers[1])\n",
        "\n",
        "# for layer in model_0.layers:\n",
        "#   print(layer.input)\n",
        "#   print(layer.output, '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEqNntPc6Jdv"
      },
      "source": [
        "#this cant be right... the output shape is supposed to be 3... it's 25 currently...\n",
        "#_, acc = model_0.evaluate(testX, testy, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXLwjvix8PwD"
      },
      "source": [
        "#ha! i was right, shape mismatch. only shows up on 'fit'\n",
        "# model_0.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# model_0.fit(trainX, trainy, epochs=50, batch_size=1, verbose=0)\n",
        "#behold imahgahd. if shapes match we can add layers from other model, (and keep them independent still)\n",
        "#no probel ez pz. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hozJ1uun9JBA"
      },
      "source": [
        "#specify where to insert layer? create model entirely from other models layers? (doesn't seem to make sense. or necessary)\n",
        "#bunch of useful tidbits here: https://stackoverflow.com/questions/49492255/how-to-replace-or-insert-intermediate-layer-in-keras-model\n",
        "# Model = Sequential() #*** 2 types of models!! Sequential, (little changing possible), Functional, (way more dynamic)\n",
        "\n",
        "# from keras.models import Model\n",
        "# input=model_0.layers[0].input\n",
        "# output=model_0.layers[1].output\n",
        "# new_model = Model(input=model_0.layers[0].input, output=model_0.layers[1].output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y06mZzXpErBL"
      },
      "source": [
        "model_0.layers[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkbK0iivZiKu"
      },
      "source": [
        "#new_model.add(model_0.layers[0])\n",
        "my_input = keras.Input(shape=(3))\n",
        "x = model_0.layers[1]\n",
        "x = model_0.layers[0](x)\n",
        "#my_output = model_0.layers[0](x)#basically this shouldn't be the output; should be a totally different output layer\n",
        "my_output = layers.Dense(3, activation=\"softmax\")(x)\n",
        "my = keras.Model(my_input, my_output, name=\"my\")\n",
        "my.summary()\n",
        "my.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "my.fit(trainX, trainy, epochs=50, batch_size=1, verbose=0)\n",
        "\n",
        "\n",
        "# new_model.add(model_1.layers[0])\n",
        "# new_model.add(model_0.layers[1])\n",
        "# new_model.add(model_0.layers[0])\n",
        "# new_model.add(model_1.layers[1])\n",
        "# new_model.add(model_0.layers[1])\n",
        "# new_model.compile(loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
        "# new_model.fit(trainX, trainy, epochs=500, batch_size=1, verbose=0)#perfomance jumps dramatically with epoch size\n",
        "_, acc = my.evaluate(testX, testy, verbose=2)\n",
        "_, acc = model_1.evaluate(testX, testy, verbose=2)\n",
        "print(my.layers)\n",
        "# 32/32 - 0s - loss: nan - accuracy: 0.3380\n",
        "# 32/32 - 0s - loss: 23.1159 - accuracy: 0.2580"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zxjjKlqBQ-1"
      },
      "source": [
        "##Sequential version for posterities sake\n",
        "# from keras.models import Model\n",
        "# new_model = Sequential()\n",
        "# # x = np.copy(model_0.layers[0])\n",
        "# # new_model.add(x)\n",
        "# #Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
        "# #but should be fine anyway\n",
        "# #new_model.add(model_0.layers[0])\n",
        "# new_model.add(model_1.layers[0])\n",
        "# new_model.add(model_0.layers[1])\n",
        "# new_model.add(model_0.layers[0])\n",
        "# new_model.add(model_1.layers[1])\n",
        "# new_model.add(model_0.layers[1])\n",
        "# new_model.compile(loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
        "# new_model.fit(trainX, trainy, epochs=500, batch_size=1, verbose=0)#perfomance jumps dramatically with epoch size\n",
        "# _, acc = new_model.evaluate(testX, testy, verbose=2)\n",
        "# _, acc = model_1.evaluate(testX, testy, verbose=2)\n",
        "# print(new_model.layers)\n",
        "# # 32/32 - 0s - loss: nan - accuracy: 0.3380\n",
        "# # 32/32 - 0s - loss: 23.1159 - accuracy: 0.2580"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8acCS6BiZg-K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VobgxywTC6Fw"
      },
      "source": [
        "#new_model.add(model_0.layers[0])\n",
        "\n",
        "for layer in new_model.layers:\n",
        "  print(layer.input)\n",
        "  \n",
        "  print(layer.output, '\\n')\n",
        "#only adding layers if the'yre unique?? how strange"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCBYmSLut6Zy"
      },
      "source": [
        "# # print(model_0.layers[1].weights)\n",
        "# import tensorflow as tf\n",
        "# import keras\n",
        "# from keras import estimator\n",
        "# estimator_model = keras.estimator.model_to_estimator(keras_model=model_0)\n",
        "# #model_copy_0 = tf.keras.models.clone_model(model_0)\n",
        "# model_copy_0 = tf.keras.models.clone_model(model_0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BicwGpu3RlFi"
      },
      "source": [
        "print(model_0.layers[1].weights)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}